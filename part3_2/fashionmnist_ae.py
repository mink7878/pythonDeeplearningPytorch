# -*- coding: utf-8 -*-
"""FashionMNIST_AE

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xNPmOydZ91gXsOWEHMT0IaAPaYjvniJa

- 원본 데이터를 생성하는 AutoEncoder 실습
- 흑백 이미지가 10개의 옷 종류로 분류돼 있는 FashionMNIST 데이터를 이용해 기본적인 MLP 구조의 AutoEncoder 모델 설계
- 순서  
> 1. 모듈 import
> 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인  
> 3. FashionMNIST 데이터 다운  
> 4. 데이터 확인 ①  
> 5. 데이터 확인 ②  
> 6. AutoEncoder(AE) 모델 설계  
> 7. Optimizer, Objective function 설정
> 8. AE 모델 학습을 진행하면서 학습 데이터에 대한 모델의 성능 확인하는 함수 정의
> 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의
> 10. AutoEncoder 학습 실행하면서 test set의 reconstructrion error 확인
"""

# 1. module import
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets

# 2. 딥러닝 모델 설계할 때 활용하는 장비 확인
if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32
EPOCHS = 10

# 3. FashionMNIST 데이터 다운로드
train_dataset = datasets.FashionMNIST(root='../data/FashionMNIST',
                               train = True,
                               download = True,
                               transform = transforms.ToTensor()) # 이미지 전처리
test_dataset = datasets.FashionMNIST(root='../data/FashionMNIST',
                              train = False,
                              transform = transforms.ToTensor())
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size = BATCH_SIZE,
                                          shuffle = False)

# 4. 데이터 확인 (1)
for (X_train, y_train) in train_loader:
  print('X_train : ', X_train.size(), 'type : ', X_train.type())
  print('X_train : ', y_train.size(), 'type : ', y_train.type())
  break

# 5. 데이터 확인 (2)
pltsize = 1
plt.figure(figsize=(10 * pltsize, pltsize))
for i in range(10):
  plt.subplot(1, 10, i+1)
  plt.axis('off')
  plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')
  plt.title('class : ' + str(y_train[i].item()))

# 6. AE 모델 설계
class AE(nn.Module):
  def __init__(self):
    super(AE, self).__init__()

    self.encoder = nn.Sequential( #nn.Sequential 이용해 인코더 단위를 한 번에 정의
        nn.Linear(28*28, 512), # input : 28*28 크기의 1차원 레이어
        nn.ReLU(),
        nn.Linear(512, 256),
        nn.ReLU(),
        nn.Linear(256, 32),
    )

    self.decoder = nn.Sequential(
        nn.Linear(32, 256),
        nn.ReLU(),
        nn.Linear(256, 512),
        nn.ReLU(),
        nn.Linear(512, 28*28),
    )

  def forward(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    
    return encoded, decoded

# 7. Optimizer, Objective Function 설정

model = AE().to(DEVICE)
optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)
criterion = nn.MSELoss()

print(model)

# AE 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train() # 학습 상태로 지정
  for batch_idx, (image, _) in enumerate(train_loader):
    image = image.view(-1, 28*28).to(DEVICE) # 2차원 이미지를 1차원 데이터로 재구성해야 함.
    target = image.view(-1, 28*28).to(DEVICE) # 이미지 데이터를 AE의 output과 비교하는 대상으로 설정하기 위해 장비에 할당
    optimizer.zero_grad()
    encoded, decoded = model(image) # AE 모델의 output 계산
    loss = criterion(decoded, target) # loss 계산
    loss.backward() # back propa 통해 계산된 gradient 값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별 할당된 gradient 값을 이용해 파라미터 값 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx*len(image),
                                                                            len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.item()))

# 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의
  
  def evaluate(model, test_loader):
    model.eval() # 평가 상태로 지정
    test_loss = 0
    real_image = []
    gen_image = []
    with torch.no_grad():
      for image, _ in test_loader:
        image = image.view(-1, 28*28).to(DEVICE)
        target = image.view(-1, 28*28).to(DEVICE)
        encoded, decoded = model(image)

        test_loss += criterion(decoded, image).item()
        real_image.append(image.to('cpu')) # 실제로 할당된 이미지를 real_image 리스트에 추가
        gen_image.append(decoded.to('cpu')) # AE 모델을 통해 생성된 이미지를 gen_image 리스트에 추가

    test_loss /= len(test_loader.dataset) # 현재까지 계산된 test_loss값을 test_loader 내에 있는 데이터 개수만큼 나눠 평균 loss 값으로 계산

    return test_loss, real_image, gen_image

# 10. AE 학습 실행하며 test set의 reconstruction error 확인

for Epoch in range(1, EPOCHS+1):
  train(model, train_loader, optimizer, log_interval=200)
  test_loss, real_image, gen_image = evaluate(model, test_loader)
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}'.format(Epoch, test_loss))
  
  f, a = plt.subplots(2, 10, figsize=(10,4))
  for i in range(10):
    img = np.reshape(real_image[0][i], (28, 28))
    a[0][i].imshow(img, cmap='gray_r')
    a[0][i].set_xticks(())
    a[0][i].set_yticks(())

  for i in range(10):
    img = np.reshape(gen_image[0][i], (28, 28))
    a[1][i].imshow(img, cmap='gray_r')
    a[1][i].set_xticks(())
    a[1][i].set_yticks(())
  plt.show()