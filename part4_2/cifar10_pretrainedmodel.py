# -*- coding: utf-8 -*-
"""cifar10_pretrainedModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mo0EJc0kGA6sGvzQIu1Kvfqqa-lotG_n

- pytorch에서 제공하고 있는 레퍼런스 모델 불러와 cifar10 dataset 분류해보자.
"""

# 1. module import

import numpy as np
import matplotlib.pyplot as plt
import torch # pytorch의 기본 모듈
import torch.nn as nn # pytorch 모듈 중 딥러닝, 즉 인공신경망 모델을 설계할 때 필요한 함수 모아 놓은 모듈
import torch.nn.functional as F # torch.nn 모듈 중에서도 자주 이용되는 함수를 F로 지정
from torchvision import transforms, datasets # 컴퓨터비전 연구 분야에서 자주 이용하는 torchvision 모듈 내 transforms, datasets 함수

# 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인

if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32 # 학습 시 32개 데이터 이용해 첫 학습, 그다음 32개 데이터로 두번째 학습, ...
EPOCHS = 10 # 전체 데이터셋 10번 반복 학습

# 'data augmentation이 적용된' cifar10 데이터 다운로드

train_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                 train = True,
                                 download = True,
                                 transform = transforms.Compose([ # Compose() : 불러오는 이미지 데이터에 전처리 및 augmentation 다양하게 적용
                                                                 transforms.RandomHorizontalFlip(), # 해당 이미지를 50%의 확률로 좌우 반전
                                                                 transforms.ToTensor(), # 0 ~ 1 사이의 값으로 정규화. 딥러닝 모델의 input으로 이용될 수 있도록 tensor형태로 변환
                                                                 transforms.Normalize((0.5, 0.5, 0.5), # 추가적인 정규화. 정규화 진행시 평균, 표준편차 필요하기 때문에 red, green, blue 순으로 평균 '0.5'씩 적용
                                                                 (0.5, 0.5, 0.5)) # red, green, blue 순으로 표준편차 '0.5'씩 적용
                                                                 
                                 ]))

# 기본적으로 학습 데이터에 이용하는 전처리 과정은 검증 데이터에도 동일하게 적용돼야 모델의 성능을 평가할 수 있다.
test_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                train = False,
                                transform = transforms.Compose([
                                                                transforms.RandomHorizontalFlip(),
                                                                transforms.ToTensor(),
                                                                transforms.Normalize((0.5, 0.5, 0.5),
                                                                (0.5, 0.5, 0.5))
                                ]))

train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)

test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = False)

import torchvision.models as models

model = models.resnet34(pretrained=False) # 모델 불러올 때 모델 구조가 ImageNet 데이터에 대해 미리 학습된 파라미터 값을 함께 불러올 수 있는데, False 설정시 모델의 구조만 불러옴. (랜덤 값으로 채우고)
num_ftrs = model.fc.in_features # 물러온 model에 대해 FC layer 부분에 접근 -> in_features는 FC layer의 input 노드 수를 num_ftr로 저장
model.fc = nn.Linear(num_ftrs, 10) # resnet34 모델의 FC layer에 해당하는 노드 수를 이용해 새로운 layer 추가 & cifar10의 클래스 개수인 10을 output으로 지정
model = model.to(DEVICE) # 기존에 존재하던 모델 불러와 새로 재구성한 모델 학습 위해 gpu 할당

for name,module in model.named_children():
    print(name)

optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 보통 Adam이 default
criterion = nn.CrossEntropyLoss() # loss를 CE로 계산하기 위함

print(model)

# 8. 모델 학습을 진행하며 학습 데이터에 대한 모델 성능 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train() # 기존에 정의한 모델 학습 상태로 지정

  for batch_idx, (image, label) in enumerate(train_loader): # 미니배치 단위로 묶인 데이터 순서대로 이용해 모델 학습
    image = image.to(DEVICE) # 미니배치 내 이미지 데이터를 장비에 할당
    label = label.to(DEVICE) # 미니배치 내 레이블 데이터 장비에 할당

    optimizer.zero_grad() 
    # 기존에 정의한 장비에 이미지, 레이블을 할당했을 때
    # 과거에 이용한 미니배치 내 이미지, 레이블 바탕으로 계산된 loss의 grad값이 optimizer에 할당 돼 있으므로 먼저 초기화하기

    output = model(image) # 장비에 할당된 이미지 데이터를 모델의 input으로 넣고 output 계산
    loss = criterion(output, label) # 계산된 output과 장비에 할당된 레이블을 기존에 정의한 CE를 이용해 loss 계산
    loss.backward() # loss 값 계산한 결과 바탕으로 역전파 통해 계산된 grad값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별로 할당된 grad 값을 이용해 파라미터값 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx*len(image),
                                                                             len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.item()))

# 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의

def evaluate(model, test_loader):
  model.eval()

  test_loss = 0
  correct = 0 # 학습 과정, 또는 학습 완료된 모델이 올바른 class로 분류한 경우 count
  with torch.no_grad(): # 평가 단계에서는 grad를 통해 파라미터 값들이 업데이트되는 현상을 방지해야 함. (grad 흐름 억제)
    for image, label in test_loader:
      image = image.to(DEVICE)
      label = label.to(DEVICE)
      output = model(image) # 크기가 10인 벡터값

      test_loss += criterion(output, label).item()
      prediction = output.max(1, keepdim=True)[1] # 계산된 벡터값 내의 가장 큰 값인 위치에 대해 해당 위치에 대응하는 class로 예측했다고 판단
      correct += prediction.eq(label.view_as(prediction)).sum().item() # 예측과 실제 레이블값을 비교해 맞으면 correct에 +1

    test_loss /= len(test_loader.dataset) # 현재까지 계산된 test_loss값을 미니배치 개수만큼 나눈 평균 loss 값
    test_accuracy = 100. * correct / len(test_loader.dataset) # test_loader 데이터 중 얼마나 맞췄는지 계산해 정확도 계산

    return test_loss, test_accuracy

# 10. 학습을 실행하며 train, test set의 loss 및 test set accuracy 확인

for Epoch in range(1, EPOCHS+1): # EPOCHS=10 번 동안 학습을 진행하며 학습 과정 속 업데이트된 파라미터 값을 바탕으로 모델의 output이 변화함.
# 각 iteration, epoch 당 loss 값이 출력되도록 설정

  train(model, train_loader, optimizer, log_interval=200) # 정의한 train 함수 실행
  test_loss, test_accuracy = evaluate(model, test_loader)
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy: {:.2f} %\n'.format(Epoch, test_loss, test_accuracy))