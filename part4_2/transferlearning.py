# -*- coding: utf-8 -*-
"""TransferLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HsLM7agtZtk2LcL4vLHDbYu02hg8DPuS

- 기본적으로 이미지와 레이블이 짝지어 있는 데이터가 적을 경우  
  => 학습이 진행되지 않거나 과적합 일어나가 쉬움.  
  => 문제점 보완 위해 이미지와 레이블이 짝지어 있는 대규모의 데이터로 학습이 이미 진행된 모델을 활용해보자.

- ResNet18 모델 구조 활용해 개미 이미지과 벌 이미지 각각 200장 분류
"""

# 1. Module import 

import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets

# 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인

if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32 # 모델 학습 시, 필요한 데이터 개수의 단위 (미니배치 1개 단위로 backpropagation 이용해 모델의 가중치 업데이트)
EPOCHS = 10 # 존재하고 있는 미니배치 전부 이용하는 횟수 10번. 즉, 전체 데이터셋 10번 반복해 학습

from google.colab import drive
drive.mount('/content/drive')

# 3. 개미와 벌을 분류하기 위해 개미 이미지 데이터와 벌 이미지 데이터 불러오기 + 전처리

data_transforms = {
    'train' : transforms.Compose([transforms.RandomResizedCrop(224), # 이미지 내 랜덤으로 선택해 224 사이즈로 변경
                                  transforms.RandomHorizontalFlip(), # 50% 확률로 좌우 반전
                                  transforms.ToTensor(), # 0과 1 사이 값으로 정규화 & 모델의 input값으로 들어갈 수 있도록 tensor 형태로 변환시켜주는 전처리 과정
                                  transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])]), # R, G, B 순으로 평균, 표준편차 0.5씩 적용
    
    'val' : transforms.Compose([transforms.CenterCrop(224), # 중앙을 기준으로 224*224 크기로 이미지 잘라내 사이즈 변경
                                 transforms.Resize(256), # 256*256 사이즈로 크기 변경
                                 transforms.ToTensor(),
                                 transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])
}

image_datasets = {x: datasets.ImageFolder("/content/drive/MyDrive/Colab Notebooks/data/hymenoptera_data", data_transforms[x]) for x in ['train', 'val']} # 이미지 불러오기
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, num_workers=0, shuffle=True) for x in ['train', 'val']} # 불러온 이미지 미니배치 단위로 구분 위해

# 4. 데이터 확인 (1)

for (X_train, y_train) in dataloaders['train']:
  print('X_train : ', X_train.size(), 'type : ', X_train.type())
  print('y_train : ', y_train.size(), 'type : ', y_train.type())
  break

"""__X_train__
- 32개의 이미지 데이터가 1개의 미니배치 구성
- h * w = 224 * 224
- 컬러 이미지 (채널=3)

__y_train__
- 32개의 이미지 데이터 각각에 대한 label 1개씩 존재


"""

y_train

# 5. 데이터 확인 (2)

pltsize = 1
plt.figure(figsize=(10 * pltsize, pltsize))

for i in range(10):
  plt.subplot(1, 10, i+1)
  plt.axis('off')
  plt.imshow(np.transpose(X_train[i], (1, 2, 0))) # [MB, CN, H, W] => [W, H, CN]
  plt.title('Class : ' + str(y_train[i].item()))

"""- label : 개미는 0, 벌은 1로 설정된 것을 알 수 있다."""

# 6. 불러온 특정 모델에 대해 학습을 진행하며 학습 데이터에 대한 모델 성능 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train()

  for batch_idx, (image, label) in enumerate(train_loader): # 미니배치 단위로 train_loader에 저장된 데이터 순서대로 학습
    image = image.to(DEVICE)
    label = label.to(DEVICE)
    optimizer.zero_grad() # 과거에 이용한 미니배치 내에 있는 이미지 데이터 ,레이블 바탕으로 계산된 loss의 grad 값이 optimizer에 할당돼 있으므로 optimizer의 grad 초기화
    output = model(image)
    loss = criterion(output, label) # loss 계산
    loss.backward() # loss 계산한 결과를 바탕으로 back prop 통해 계산된 grad 값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별 할당된 grad 값 이용해 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx * len(image), 
                                                                            len(train_loader.dataset), 100. * batch_idx / len(train_loader),
                                                                            loss.item())
      )

# 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의

def evaluate(model, test_loader):
  model.eval()
  test_loss = 0 # loss 값 계산 위해 임시 설정
  correct = 0 # 학습 완료된 모델이 올바른 class로 분류한 경우 count

  with torch.no_grad(): # 평가하는 단계에서는 grad를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 grad 흐름 억제
    for image, label in test_loader:
      image = image.to(DEVICE)
      label = label.to(DEVICE)
      output = model(image)
      test_loss += criterion(output, label).item() # loss 계산한 값을 test_loss에 더해 업데이트
      prediction = output.max(1, keepdim=True)[1] # 모델의 output값은 크기가 10인 벡터. 계산된 벡터 값 내 max 값에 해당하는 클래스로 예측했다고 판단
      correct += prediction.eq(label.view_as(prediction)).sum().item() # 클래스 비교해 맞았으면 correct에 더해 올바르게 예측한 횟수 저장
  
  test_loss /= len(test_loader.dataset) # test_loss 값을 test_loader 내에 있는 미니배치 개수만큼 나눠 평균 loss 값으로 계산
  test_accuracy = 100. * correct / len(test_loader.dataset) # test_loader 데이터 중 얼마나 맞췄는지 정확도 계산
  
  return test_loss, test_accuracy

# 8. 파이토치 내에서 제공하는 미리 학습되지 않은 ResNet18 모델 불러온 후 output 크기 설정

import torchvision.models as models

model = models.resnet18(pretrained=False).cuda() # False : 모델 구조만 불러오고, 모델 구조 내에 있는 파라미터는 특정 initializer에서 랜덤으로 샘플링한 값을 이용해 모델 불러옴
num_ftrs = model.fc.in_features # fc layer 구성하고 있는 부분에 접근. fc layer의 input에 해당하는 노드 수를 num_ftrs로 지정
model.fc = nn.Linear(num_ftrs, 2) # 개미/벌 분류하기 때문에 2로 output 설정
model = model.cuda()

# 9. optimizer, objective function 설정

optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()

print(model)

# 10. 미리 학습되지 않은 ResNet18 학습을 실행하며 train, test set의 loss 및 test set accuracy 확인하기

for Epoch in range(1, EPOCHS + 1):
  train(model, dataloaders['train'], optimizer, log_interval=5)
  test_loss, test_accracy = evaluate(model, dataloaders['val'])
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy : {:.2f} % \n'.format(
      Epoch, test_loss, test_accracy))

"""- 미리 학습되지 않은 모델 구조만 이용해 학습한 결과  
  => 검증 데이터셋 기준 약 63.5% 수준의 정확도 확인


- 그럼, 이번에는 ImageNet 데이터셋으로 미리 학습된 파라미터를 불러와 새로운 데이터를 분류할 수 있도록 fine-tuning하는 과정을 실습해보자.
"""

# 11. ImageNet 데이터로 미리 학습된 ResNet18 모델을 불러온 후 개미, 벌 이미지 데이터에 맞게 fine tuning 해 보기

model = models.resnet18(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)
model = model.cuda()

optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
EPOCHS = 10
for Epoch in range(1, EPOCHS + 1):
  train(model, dataloaders['train'], optimizer, log_interval=5)
  test_loss, test_accracy = evaluate(model, dataloaders['val'])
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy : {:.2f} % \n'.format(
      Epoch, test_loss, test_accracy))

"""- 미리 학습된, 모델 구조와 파라미터를 함께 이용해 학습한 결과  
  => 검증 데이터셋 기준 약 95.5% 수준의 정확도 확인 가능
"""