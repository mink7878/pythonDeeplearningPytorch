# -*- coding: utf-8 -*-
"""cifar10_resnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jy6BxSIq6Xf8-tJVAfLp4FZYLquo6uNE
"""

# 1. module import

import numpy as np
import matplotlib.pyplot as plt
import torch # pytorch의 기본 모듈
import torch.nn as nn # pytorch 모듈 중 딥러닝, 즉 인공신경망 모델을 설계할 때 필요한 함수 모아 놓은 모듈
import torch.nn.functional as F # torch.nn 모듈 중에서도 자주 이용되는 함수를 F로 지정
from torchvision import transforms, datasets # 컴퓨터비전 연구 분야에서 자주 이용하는 torchvision 모듈 내 transforms, datasets 함수

# 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인

if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32 # 학습 시 32개 데이터 이용해 첫 학습, 그다음 32개 데이터로 두번째 학습, ...
EPOCHS = 10 # 전체 데이터셋 10번 반복 학습

# 'data augmentation이 적용된' cifar10 데이터 다운로드

train_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                 train = True,
                                 download = True,
                                 transform = transforms.Compose([ # Compose() : 불러오는 이미지 데이터에 전처리 및 augmentation 다양하게 적용
                                                                 transforms.RandomHorizontalFlip(), # 해당 이미지를 50%의 확률로 좌우 반전
                                                                 transforms.ToTensor(), # 0 ~ 1 사이의 값으로 정규화. 딥러닝 모델의 input으로 이용될 수 있도록 tensor형태로 변환
                                                                 transforms.Normalize((0.5, 0.5, 0.5), # 추가적인 정규화. 정규화 진행시 평균, 표준편차 필요하기 때문에 red, green, blue 순으로 평균 '0.5'씩 적용
                                                                 (0.5, 0.5, 0.5)) # red, green, blue 순으로 표준편차 '0.5'씩 적용
                                                                 
                                 ]))

# 기본적으로 학습 데이터에 이용하는 전처리 과정은 검증 데이터에도 동일하게 적용돼야 모델의 성능을 평가할 수 있다.
test_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                train = False,
                                transform = transforms.Compose([
                                                                transforms.RandomHorizontalFlip(),
                                                                transforms.ToTensor(),
                                                                transforms.Normalize((0.5, 0.5, 0.5),
                                                                (0.5, 0.5, 0.5))
                                ]))

train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)

test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = False)

# 4. 데이터 확인 - (1)

for (X_train, y_train) in train_loader:
  print('X_train : ', X_train.size(), 'type : ', X_train.type())
  print('y_train : ', y_train.size(), 'type : ', y_train.type())
  break

# 5. 데이터 확인 - (2)

pltsize = 2
plt.figure(figsize=(10 * pltsize, pltsize))
for i in range(10):
  plt.subplot(1, 10, i+1)
  plt.axis('off')
  plt.imshow(np.transpose(X_train[i],(1,2,0))) # [mini-batch, Channel, Height, Width]
  plt.title('Class : ' + str(y_train[i].item()))

# 6. ResNet 모델 설계

# ResNet은 내부에 반복적으로 이용하는 block을 바탕으로 구성
# 따라서 반복적으로 사용하는 block(BasicBlock)을 먼저 정의한 후 정의된 block을 바탕으로 ResNet 구현

class BasicBlock(nn.Module):
  def __init__(self, in_planes, planes, stride = 1):
    super(BasicBlock, self).__init__()
    self.conv1 = nn.Conv2d(in_planes, planes, # in_planes : input으로 이용되는 데이터의 채널수 # planes : filter의 개수
                           kernel_size=3, # 사용하는 filter의 크기 3*3으로 설정
                           stride=stride,
                           padding=1,
                           bias=False)
    self.bn1 = nn.BatchNorm2d(planes) # 각 layer마다 input의 분포가 달라짐에 따라 학습 속도가 현저히 느려지는 것을 방지하기 위해 이용되는 기법. 학습 안정적으로 진행
    self.conv2 = nn.Conv2d(planes, planes,
                           kernel_size=3,
                           stride=1,
                           padding=1,
                           bias=False)
    self.bn2 = nn.BatchNorm2d(planes)

    # ResNet의 특징은 
    self.shortcut = nn.Sequential() 
    if stride != 1 or in_planes != planes:
      self.shortcut = nn.Sequential(
          nn.Conv2d(in_planes, planes,
                    kernel_size=1,
                    stride=stride,
                    bias=False),
         nn.BatchNorm2d(planes)
      )

  def forward(self, x):
    out = F.relu(self.bn1(self.conv1(x)))
    out = self.bn2(self.conv2(out))
    out += self.shortcut(x)
    out = F.relu(out)
    
    return out

class ResNet(nn.Module):
  def __init__(self, num_classes=10):
    super(ResNet, self).__init__()
    self.in_planes = 16

    self.conv1 = nn.Conv2d(3, 16,
                           kernel_size=3,
                           stride=1,
                           padding=1,
                           bias=False)
    self.bn1 = nn.BatchNorm2d(16)
    self.layer1 = self._make_layer(16, 2, stride=1)
    self.layer2 = self._make_layer(32, 2, stride=2)
    self.layer3 = self._make_layer(64, 2, stride=2)
    self.linear = nn.Linear(64, num_classes)

  def _make_layer(self, planes, num_blocks, stride):
    strides = [stride] + [1] * (num_blocks - 1)
    layers = []
    for stride in strides:
      layers.append(BasicBlock(self.in_planes, planes, stride))
      self.in_planes = planes

      return nn.Sequential(*layers)

  def forward(self, x):
    out = F.relu(self.bn1(self.conv1(x)))
    out = self.layer1(out)
    out = self.layer2(out)
    out = self.layer3(out)
    out = F.avg_pool2d(out, 8)
    out = out.view(out.size(0), -1)
    out = self.linear(out)

    return out

# 7. optimizer, objective function 설정

model = ResNet(64).to(DEVICE) # DEVICE 장비 이용해 CNN 모델 완성하기 위해 할당
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 보통 Adam이 default
criterion = nn.CrossEntropyLoss() # loss를 CE로 계산하기 위함

print(model)

# 8. 모델 학습을 진행하며 학습 데이터에 대한 모델 성능 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train() # 기존에 정의한 모델 학습 상태로 지정

  for batch_idx, (image, label) in enumerate(train_loader): # 미니배치 단위로 묶인 데이터 순서대로 이용해 MLP 모델 학습
    image = image.to(DEVICE) # 미니배치 내 이미지 데이터를 장비에 할당
    label = label.to(DEVICE) # 미니배치 내 레이블 데이터 장비에 할당

    optimizer.zero_grad() 
    # 기존에 정의한 장비에 이미지, 레이블을 할당했을 때
    # 과거에 이용한 미니배치 내 이미지, 레이블 바탕으로 계산된 loss의 grad값이 optimizer에 할당 돼 있으므로 먼저 초기화하기

    output = model(image) # 장비에 할당된 이미지 데이터를 모델의 input으로 넣고 output 계산
    loss = criterion(output, label) # 계산된 output과 장비에 할당된 레이블을 기존에 정의한 CE를 이용해 loss 계산
    loss.backward() # loss 값 계산한 결과 바탕으로 역전파 통해 계산된 grad값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별로 할당된 grad 값을 이용해 파라미터값 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx*len(image),
                                                                             len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.item()))

# 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의

def evaluate(model, test_loader):
  model.eval()

  test_loss = 0
  correct = 0 # 학습 과정, 또는 학습 완료된 모델이 올바른 class로 분류한 경우 count
  with torch.no_grad(): # 평가 단계에서는 grad를 통해 파라미터 값들이 업데이트되는 현상을 방지해야 함. (grad 흐름 억제)
    for image, label in test_loader:
      image = image.to(DEVICE)
      label = label.to(DEVICE)
      output = model(image) # 크기가 10인 벡터값

      test_loss += criterion(output, label).item()
      prediction = output.max(1, keepdim=True)[1] # 계산된 벡터값 내의 가장 큰 값인 위치에 대해 해당 위치에 대응하는 class로 예측했다고 판단
      correct += prediction.eq(label.view_as(prediction)).sum().item() # 예측과 실제 레이블값을 비교해 맞으면 correct에 +1

    test_loss /= len(test_loader.dataset) # 현재까지 계산된 test_loss값을 미니배치 개수만큼 나눈 평균 loss 값
    test_accuracy = 100. * correct / len(test_loader.dataset) # test_loader 데이터 중 얼마나 맞췄는지 계산해 정확도 계산

    return test_loss, test_accuracy

# 10. 학습을 실행하며 train, test set의 loss 및 test set accuracy 확인

for Epoch in range(1, EPOCHS+1): # EPOCHS=10 번 동안 학습을 진행하며 학습 과정 속 업데이트된 파라미터 값을 바탕으로 모델의 output이 변화함.
# 각 iteration, epoch 당 loss 값이 출력되도록 설정

  train(model, train_loader, optimizer, log_interval=200) # 정의한 train 함수 실행
  test_loss, test_accuracy = evaluate(model, test_loader)
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy: {:.2f} %\n'.format(Epoch, test_loss, test_accuracy))