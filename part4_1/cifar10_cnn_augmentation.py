# -*- coding: utf-8 -*-
"""cifar10_CNN_augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-I43o8wNEIdwhLS9Litws9XEJDEf1lCW

- 추가로 모델의 성능을 향상시킬 수 있는 방법 중 __data augmentation__ 적용해보자.
- data augmentation  
: 자르기, 회전하기, 돌리기 등 사람의 눈으로 봤을 때 동일한 클래스로 분류할 수 있는 수준의 변형을 가하는 것.
"""

# 1. module import

import numpy as np
import matplotlib.pyplot as plt
import torch # pytorch의 기본 모듈
import torch.nn as nn # pytorch 모듈 중 딥러닝, 즉 인공신경망 모델을 설계할 때 필요한 함수 모아 놓은 모듈
import torch.nn.functional as F # torch.nn 모듈 중에서도 자주 이용되는 함수를 F로 지정
from torchvision import transforms, datasets # 컴퓨터비전 연구 분야에서 자주 이용하는 torchvision 모듈 내 transforms, datasets 함수

# 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인

if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32 # MLP 학습 시 32개 데이터 이용해 첫 학습, 그다음 32개 데이터로 두번째 학습, ...
EPOCHS = 10 # 전체 데이터셋 10번 반복 학습

# 'data augmentation이 적용된' cifar10 데이터 다운로드

train_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                 train = True,
                                 download = True,
                                 transform = transforms.Compose([ # Compose() : 불러오는 이미지 데이터에 전처리 및 augmentation 다양하게 적용
                                                                 transforms.RandomHorizontalFlip(), # 해당 이미지를 50%의 확률로 좌우 반전
                                                                 transforms.ToTensor(), # 0 ~ 1 사이의 값으로 정규화. 딥러닝 모델의 input으로 이용될 수 있도록 tensor형태로 변환
                                                                 transforms.Normalize((0.5, 0.5, 0.5), # 추가적인 정규화. 정규화 진행시 평균, 표준편차 필요하기 때문에 red, green, blue 순으로 평균 '0.5'씩 적용
                                                                 (0.5, 0.5, 0.5)) # red, green, blue 순으로 표준편차 '0.5'씩 적용
                                                                 
                                 ]))

# 기본적으로 학습 데이터에 이용하는 전처리 과정은 검증 데이터에도 동일하게 적용돼야 모델의 성능을 평가할 수 있다.
test_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                train = False,
                                transform = transforms.Compose([
                                                                transforms.RandomHorizontalFlip(),
                                                                transforms.ToTensor(),
                                                                transforms.Normalize((0.5, 0.5, 0.5),
                                                                (0.5, 0.5, 0.5))
                                ]))

train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)

test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = False)

# 4. 데이터 확인 - (1)

for (X_train, y_train) in train_loader:
  print('X_train : ', X_train.size(), 'type : ', X_train.type())
  print('y_train : ', y_train.size(), 'type : ', y_train.type())
  break

# 5. 데이터 확인 - (2)

pltsize = 2
plt.figure(figsize=(10 * pltsize, pltsize))
for i in range(10):
  plt.subplot(1, 10, i+1)
  plt.axis('off')
  plt.imshow(np.transpose(X_train[i],(1,2,0))) # [mini-batch, Channel, Height, Width]
  plt.title('Class : ' + str(y_train[i].item()))

# 6. CNN 모델 설계

class CNN(nn.Module): # nn.Module 클래스 상속
  def __init__(self): # CNN 클래스의 인스턴스를 생성했을 때 지니는 성질 정의해주는 메서드
    super(CNN, self).__init__() # nn.Module 내에 있는 메서드를 상속받아 이용
    # nn.Conv2d 메서드 이용해 conv 연산하는 'filter' 정의
    self.conv1 = nn.Conv2d(in_channels=3, 
                           out_channels=8, # filter 개수만큼 output의 depth 정해지므로 depth=8인 피처맵 생성될 것.
                           kernel_size=3, # 필터 크기 설정 # 3*3의 filter
                           padding=1) # 이미지 구석 부분과 중앙 부분이 conv 연산되는 횟수 동일하게 맞춰줌.
    self.conv2 = nn.Conv2d(in_channels=8, 
                           out_channels=16, 
                           kernel_size=3, 
                           padding=1)
    self.pool = nn.MaxPool2d(kernel_size=2, # 2차원의 feature map 내에서 지정한 크기 내 가장 큰 feature map 값만 이용하겠다. (2*2 크기 filter)
                             stride=2) # feature map 내에서 2단위로 움직임
    self.fc1 = nn.Linear(8*8*16, 64)
    self.fc2 = nn.Linear(64, 32)
    self.fc3 = nn.Linear(32, 10)

  def forward(self, x):
    x = self.conv1(x)
    x = F.relu(x)
    x = self.pool(x) # 생성된 feature map에 down sampling 적용
    x = self.conv2(x)
    x = F.relu(x)
    x = self.pool(x)
    # 여기까지 생성된 feature map의 크기 = 8*8*16, 즉 8*8의 2차원 데이터 16개가 겹쳐있음.

    x = x.view(-1, 8*8*16) # 1치원 데이터로 변환                                
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    x = F.log_softmax(x)

    return x

# 7. optimizer, objective function 설정

model = CNN().to(DEVICE) # DEVICE 장비 이용해 CNN 모델 완성하기 위해 할당
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 보통 Adam이 default
criterion = nn.CrossEntropyLoss() # loss를 CE로 계산하기 위함

print(model)

# 8. 모델 학습을 진행하며 학습 데이터에 대한 모델 성능 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train() # 기존에 정의한 CNN 모델 학습 상태로 지정

  for batch_idx, (image, label) in enumerate(train_loader): # 미니배치 단위로 묶인 데이터 순서대로 이용해 MLP 모델 학습
    image = image.to(DEVICE) # 미니배치 내 이미지 데이터를 장비에 할당
    label = label.to(DEVICE) # 미니배치 내 레이블 데이터 장비에 할당

    optimizer.zero_grad() 
    # 기존에 정의한 장비에 이미지, 레이블을 할당했을 때
    # 과거에 이용한 미니배치 내 이미지, 레이블 바탕으로 계산된 loss의 grad값이 optimizer에 할당 돼 있으므로 먼저 초기화하기

    output = model(image) # 장비에 할당된 이미지 데이터를 모델의 input으로 넣고 output 계산
    loss = criterion(output, label) # 계산된 output과 장비에 할당된 레이블을 기존에 정의한 CE를 이용해 loss 계산
    loss.backward() # loss 값 계산한 결과 바탕으로 역전파 통해 계산된 grad값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별로 할당된 grad 값을 이용해 파라미터값 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx*len(image),
                                                                             len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.item()))

# 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의

def evaluate(model, test_loader):
  model.eval()

  test_loss = 0
  correct = 0 # 학습 과정, 또는 학습 완료된 MLP 모델이 올바른 class로 분류한 경우 count
  with torch.no_grad(): # 평가 단계에서는 grad를 통해 파라미터 값들이 업데이트되는 현상을 방지해야 함. (grad 흐름 억제)
    for image, label in test_loader:
      image = image.to(DEVICE)
      label = label.to(DEVICE)
      output = model(image) # 크기가 10인 벡터값

      test_loss += criterion(output, label).item()
      prediction = output.max(1, keepdim=True)[1] # 계산된 벡터값 내의 가장 큰 값인 위치에 대해 해당 위치에 대응하는 class로 예측했다고 판단
      correct += prediction.eq(label.view_as(prediction)).sum().item() # 예측과 실제 레이블값을 비교해 맞으면 correct에 +1

    test_loss /= len(test_loader.dataset) # 현재까지 계산된 test_loss값을 미니배치 개수만큼 나눈 평균 loss 값
    test_accuracy = 100. * correct / len(test_loader.dataset) # test_loader 데이터 중 얼마나 맞췄는지 계산해 정확도 계산

    return test_loss, test_accuracy

# 10. 학습을 실행하며 train, test set의 loss 및 test set accuracy 확인

for Epoch in range(1, EPOCHS+1): # EPOCHS=10 번 동안 학습을 진행하며 학습 과정 속 업데이트된 파라미터 값을 바탕으로 MLP 모델의 output이 변화함.
# 각 iteration, epoch 당 loss 값이 출력되도록 설정

  train(model, train_loader, optimizer, log_interval=200) # 정의한 train 함수 실행
  test_loss, test_accuracy = evaluate(model, test_loader)
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy: {:.2f} %\n'.format(Epoch, test_loss, test_accuracy))