# -*- coding: utf-8 -*-
"""cifar10_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/169LDNcO5JnxjXxB-Lc8dkRUDhAHLfG-W

- cifar10 : 컬러 이미지 중 딥러닝 실험용 데이터로 자주 쓰이는 데이터 중 하나
- 비행기, 자동차, 새, 고양이, 사슴, 개, 개구리, 말, 배, 트럭 10개의 class로 구성
- 각 class별 5000장의 이미지인 학습 데이터셋 & 1000장의 이미지인 검증 데이터셋  
  = 5만 장의 학습 데이터셋 & 1만 장의 검증 데이터셋
- 단순한 구조의 흑백 이미지를 잘 분류할 수 있었던 MLP 모델이 컬러 이미지도 잘 분류할 수 있는지 확인해보자.
"""

# 1. module import

import numpy as np
import matplotlib.pyplot as plt
import torch # pytorch의 기본 모듈
import torch.nn as nn # pytorch 모듈 중 딥러닝, 즉 인공신경망 모델을 설계할 때 필요한 함수 모아 놓은 모듈
import torch.nn.functional as F # torch.nn 모듈 중에서도 자주 이용되는 함수를 F로 지정
from torchvision import transforms, datasets # 컴퓨터비전 연구 분야에서 자주 이용하는 torchvision 모듈 내 transforms, datasets 함수

# 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인

if torch.cuda.is_available():
  DEVICE = torch.device('cuda')
else:
  DEVICE = torch.device('cpu')

print('Using PyTorch version : ', torch.__version__, 'Device : ', DEVICE)

BATCH_SIZE = 32 # MLP 학습 시 32개 데이터 이용해 첫 학습, 그다음 32개 데이터로 두번째 학습, ...
EPOCHS = 10 # 전체 데이터셋 10번 반복 학습

# cifar10 데이터 다운로드
train_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                 train = True,
                                 download = True,
                                 transform = transforms.ToTensor())
                                 
test_dataset = datasets.CIFAR10(root='../data/CIFAR10',
                                train = False,
                                transform = transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                           batch_size = BATCH_SIZE,
                                           shuffle = False)

# 4. 데이터 확인 - (1)

for (X_train, y_train) in train_loader:
  print('X_train : ', X_train.size(), 'type : ', X_train.type())
  print('y_train : ', y_train.size(), 'type : ', y_train.type())
  break

"""- X_train
- 32개 이미지 데이터가 1개의 미니배치를 구성
- 가로, 세로 32개의 픽셀로 구성
- 채널 3이므로 RGB 이미지 데이터  

- y_train
- 32개의 이미지 데이터 각각에 label값이 1개씩 존재하기 때문에 32개의 값 가짐.
"""

# 5. 데이터 확인 - (2)

pltsize = 2
plt.figure(figsize=(10 * pltsize, pltsize))
for i in range(10):
  plt.subplot(1, 10, i+1)
  plt.axis('off')
  plt.imshow(np.transpose(X_train[i],(1,2,0))) # [mini-batch, Channel, Height, Width]
  plt.title('Class : ' + str(y_train[i].item()))

# 6. MLP 모델 설계

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.fc1 = nn.Linear(32*32*3, 512) # MLP 모델은 1차원 벡터값을 입력으로 받을 수 있음.
    self.fc2 = nn.Linear(512, 256)
    self.fc3 = nn.Linear(256, 10)

  def forward(self, x):
    x = x.view(-1, 32*32*3) # MLP 모델은 1차원 벡터값을 입력으로 받을 수 있음. -> flatten
    x = self.fc1(x)
    x = F.relu(x)
    x = self.fc2(x)
    x = F.relu(x)
    x = self.fc3(x)
    x = F.log_softmax(x, dim=1) # softmax 이용해 확률값 계산 (log 사용하는 이유는 역전파 시 학습 원활하게 하기 위함)

    return x

# 7. optimizer, objective function 설정

model = Net().to(DEVICE) # DEVICE 장비 이용해 MLP 모델 완성하기 위해 할당
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 보통 Adam이 default
criterion = nn.CrossEntropyLoss() # loss를 CE로 계산하기 위함

print(model)

# 8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능 확인하는 함수 정의

def train(model, train_loader, optimizer, log_interval):
  model.train() # 기존에 정의한 MLP 모델 학습 상태로 지정

  for batch_idx, (image, label) in enumerate(train_loader): # 미니배치 단위로 묶인 데이터 순서대로 이용해 MLP 모델 학습
    image = image.to(DEVICE) # 미니배치 내 이미지 데이터를 장비에 할당
    label = label.to(DEVICE) # 미니배치 내 레이블 데이터 장비에 할당

    optimizer.zero_grad() 
    # 기존에 정의한 장비에 이미지, 레이블을 할당했을 때
    # 과거에 이용한 미니배치 내 이미지, 레이블 바탕으로 계산된 loss의 grad값이 optimizer에 할당 돼 있으므로 먼저 초기화하기

    output = model(image) # 장비에 할당된 이미지 데이터를 모델의 input으로 넣고 output 계산
    loss = criterion(output, label) # 계산된 output과 장비에 할당된 레이블을 기존에 정의한 CE를 이용해 loss 계산
    loss.backward() # loss 값 계산한 결과 바탕으로 역전파 통해 계산된 grad값을 각 파라미터에 할당
    optimizer.step() # 각 파라미터별로 할당된 grad 값을 이용해 파라미터값 업데이트

    if batch_idx % log_interval == 0:
      print('Train Epoch : {} [{}/{}({:.0f}%)]\tTrain Loss : {:.6f}'.format(Epoch, batch_idx*len(image),
                                                                             len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.item()))

# 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능 확인하는 함수 정의

def evaluate(model, test_loader):
  model.eval()

  test_loss = 0
  correct = 0 # 학습 과정, 또는 학습 완료된 MLP 모델이 올바른 class로 분류한 경우 count
  with torch.no_grad(): # 평가 단계에서는 grad를 통해 파라미터 값들이 업데이트되는 현상을 방지해야 함. (grad 흐름 억제)
    for image, label in test_loader:
      image = image.to(DEVICE)
      label = label.to(DEVICE)
      output = model(image) # 크기가 10인 벡터값

      test_loss += criterion(output, label).item()
      prediction = output.max(1, keepdim=True)[1] # 계산된 벡터값 내의 가장 큰 값인 위치에 대해 해당 위치에 대응하는 class로 예측했다고 판단
      correct += prediction.eq(label.view_as(prediction)).sum().item() # 예측과 실제 레이블값을 비교해 맞으면 correct에 +1

    test_loss /= len(test_loader.dataset) # 현재까지 계산된 test_loss값을 미니배치 개수만큼 나눈 평균 loss 값
    test_accuracy = 100. * correct / len(test_loader.dataset) # test_loader 데이터 중 얼마나 맞췄는지 계산해 정확도 계산

    return test_loss, test_accuracy

# 10. MLP 학습을 실행하며 train, test set의 loss 및 test set accuracy 확인

for Epoch in range(1, EPOCHS+1): # EPOCHS=10 번 동안 학습을 진행하며 학습 과정 속 업데이트된 파라미터 값을 바탕으로 MLP 모델의 output이 변화함.
# 각 iteration, epoch 당 loss 값이 출력되도록 설정

  train(model, train_loader, optimizer, log_interval=200) # 정의한 train 함수 실행
  test_loss, test_accuracy = evaluate(model, test_loader)
  print('\n[EPOCH : {}], \tTest Loss : {:.4f}, \tTest Accuracy: {:.2f} %\n'.format(Epoch, test_loss, test_accuracy))

"""- 학습이 완료됐을 때 test_loader 내에 있는 데이터에 대해 약 49% 수준의 정확도를 나타내는 것을 확인할 수 있음."""